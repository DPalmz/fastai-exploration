{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#fastai imports\n",
    "!pip install -Uq transformers\n",
    "!pip install -Uq datasets\n",
    "\n",
    "!pip install -Uq fastxtend\n",
    "\n",
    "\n",
    "\n",
    "from fastxtend.optimizer.all import *\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    " #   for filename in filenames:\n",
    "  #      print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_checkpoint = \"facebook/bart-large-cnn\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b2db557234442eb5c97baedc739ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5788172f3e34469b8d2f3f5e86046fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d2ada54e784846a9c52a7deaf1fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xsum/default to C:/Users/Dylan/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39227fe5507e45409537f77cf495041e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e84127428db48b997c59dce6632319b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc144901fb24400288eba47fa497b0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be385467c7494cb3aaf0ff42c4f2650c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd60cb0dcfbc4e8ab7520026eb0075b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9d7f3bad9f4fe695e107c5ab62422b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xsum downloaded and prepared to C:/Users/Dylan/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15da5344f71455da6cac7247ebde8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"xsum\")\n",
    "\n",
    "\n",
    "dataset\n",
    "#from fastai.text.all import *\n",
    "#path = untar_data(URLs.AG_NEWS)\n",
    "#path.ls()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\\nWorkers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\\nThe Welsh Government said more people than ever were getting help to address housing problems.\\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\\nPrison Link Cymru, which helps people find accommodation after their release, said things were generally ...</td>\n",
       "      <td>There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.</td>\n",
       "      <td>38264402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Officers searched properties in the Waterfront Park and Colonsay View areas of the city on Wednesday.\\nDetectives said three firearms, ammunition and a five-figure sum of money were recovered.\\nA 26-year-old man who was arrested and charged appeared at Edinburgh Sheriff Court on Thursday.</td>\n",
       "      <td>A man has appeared in court after firearms, ammunition and cash were seized by police in Edinburgh.</td>\n",
       "      <td>34227252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jordan Hill, Brittany Covington and Tesfaye Cooper, all 18, and Tanishia Covington, 24, appeared in a Chicago court on Friday.\\nThe four have been charged with hate crimes and aggravated kidnapping and battery, among other things.\\nAn online fundraiser for their victim has collected $51,000 (Â£42,500) so far.\\nDenying the four suspects bail, Judge Maria Kuriakos Ciesil asked: \"Where was your sense of decency?\"\\nProsecutors told the court the beating started in a van and continued at a house, where the suspects allegedly forced the 18-year-old white victim, who suffers from schizophrenia an...</td>\n",
       "      <td>Four people accused of kidnapping and torturing a mentally disabled man in a \"racially motivated\" attack streamed on Facebook have been denied bail.</td>\n",
       "      <td>38537698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 48-year-old former Arsenal goalkeeper played for the Royals for four years.\\nHe was appointed youth academy director in 2000 and has been director of football since 2003.\\nA West Brom statement said: \"He played a key role in the Championship club twice winning promotion to the Premier League in 2006 and 2012.\"</td>\n",
       "      <td>West Brom have appointed Nicky Hammond as technical director, ending his 20-year association with Reading.</td>\n",
       "      <td>36175342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restoring the function of the organ - which helps control blood sugar levels - reversed symptoms of diabetes in animal experiments.\\nThe study, published in the journal Cell, says the diet reboots the body.\\nExperts said the findings were \"potentially very exciting\" as they could become a new treatment for the disease.\\nThe experiments were on mice put on a modified form of the \"fasting-mimicking diet\".\\nWhen people go on it they spend five days on a low calorie, low protein, low carbohydrate but high unsaturated-fat diet.\\nIt resembles a vegan diet with nuts and soups, but with around 800...</td>\n",
       "      <td>The pancreas can be triggered to regenerate itself through a type of fasting diet, say US researchers.</td>\n",
       "      <td>39070183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  document  \\\n",
       "0  Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\\nWorkers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\\nThe Welsh Government said more people than ever were getting help to address housing problems.\\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\\nPrison Link Cymru, which helps people find accommodation after their release, said things were generally ...   \n",
       "1                                                                                                                                                                                                                                                                                                                        Officers searched properties in the Waterfront Park and Colonsay View areas of the city on Wednesday.\\nDetectives said three firearms, ammunition and a five-figure sum of money were recovered.\\nA 26-year-old man who was arrested and charged appeared at Edinburgh Sheriff Court on Thursday.   \n",
       "2  Jordan Hill, Brittany Covington and Tesfaye Cooper, all 18, and Tanishia Covington, 24, appeared in a Chicago court on Friday.\\nThe four have been charged with hate crimes and aggravated kidnapping and battery, among other things.\\nAn online fundraiser for their victim has collected $51,000 (Â£42,500) so far.\\nDenying the four suspects bail, Judge Maria Kuriakos Ciesil asked: \"Where was your sense of decency?\"\\nProsecutors told the court the beating started in a van and continued at a house, where the suspects allegedly forced the 18-year-old white victim, who suffers from schizophrenia an...   \n",
       "3                                                                                                                                                                                                                                                                                              The 48-year-old former Arsenal goalkeeper played for the Royals for four years.\\nHe was appointed youth academy director in 2000 and has been director of football since 2003.\\nA West Brom statement said: \"He played a key role in the Championship club twice winning promotion to the Premier League in 2006 and 2012.\"   \n",
       "4  Restoring the function of the organ - which helps control blood sugar levels - reversed symptoms of diabetes in animal experiments.\\nThe study, published in the journal Cell, says the diet reboots the body.\\nExperts said the findings were \"potentially very exciting\" as they could become a new treatment for the disease.\\nThe experiments were on mice put on a modified form of the \"fasting-mimicking diet\".\\nWhen people go on it they spend five days on a low calorie, low protein, low carbohydrate but high unsaturated-fat diet.\\nIt resembles a vegan diet with nuts and soups, but with around 800...   \n",
       "\n",
       "                                                                                                                                                summary  \\\n",
       "0                                                       There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.   \n",
       "1                                                   A man has appeared in court after firearms, ammunition and cash were seized by police in Edinburgh.   \n",
       "2  Four people accused of kidnapping and torturing a mentally disabled man in a \"racially motivated\" attack streamed on Facebook have been denied bail.   \n",
       "3                                            West Brom have appointed Nicky Hammond as technical director, ending his 20-year association with Reading.   \n",
       "4                                                The pancreas can be triggered to regenerate itself through a type of fasting diet, say US researchers.   \n",
       "\n",
       "         id  \n",
       "0  38264402  \n",
       "1  34227252  \n",
       "2  38537698  \n",
       "3  36175342  \n",
       "4  39070183  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['test'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(0.2) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\NLP\\fastai vision\\fastai-nlp-summarization.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#train_split = dataset['test']['document'][:int(len(dataset['test']['document']) * .80)]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#test_split = dataset['test']['document'][int(len(dataset['test']['document']) * .80):]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m extra, dds \u001b[39m=\u001b[39m train_test_split(dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dds\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2417\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2414\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2417\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2419\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2420\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2421\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2422\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\sklearn\\utils\\validation.py:378\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 378\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\sklearn\\utils\\validation.py:329\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[0;32m    319\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[39m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    330\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\sklearn\\utils\\validation.py:329\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[0;32m    319\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[39m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    330\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\sklearn\\utils\\validation.py:269\u001b[0m, in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 269\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    270\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSingleton array \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m cannot be considered a valid collection.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m x\n\u001b[0;32m    271\u001b[0m         )\n\u001b[0;32m    272\u001b[0m     \u001b[39m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[39m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], numbers\u001b[39m.\u001b[39mIntegral):\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(0.2) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "#train_split = dataset['test']['document'][:int(len(dataset['test']['document']) * .80)]\n",
    "#test_split = dataset['test']['document'][int(len(dataset['test']['document']) * .80):]\n",
    "\n",
    "#tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "from sklearn.model_selection import train_test_split\n",
    "extra, dds = train_test_split(dataset[\"train\"], 0.2)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"document\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"summary\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"labels_mask\"] = labels[\"attention_mask\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e83bc7c2d440a7807afd40e00decdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371ab88975214fefbb63cfa47d8e45c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fe19f48fd84e959c658b0cf00dde38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: dill in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (2022.10.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (2.6.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (0.10.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from evaluate) (1.23.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from datasets>=2.0.0->evaluate) (10.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "     -------------------------------------- 124.6/124.6 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from rouge_score) (1.23.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from click->nltk->rouge_score) (0.4.5)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=63755616a1ef33e1b9666d1d6db8eeee555cd3751b90e009d13a5c0aa2670ab0\n",
      "  Stored in directory: c:\\users\\dylan\\appdata\\local\\pip\\cache\\wheels\\5f\\dd\\89\\461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "Successfully installed absl-py-1.3.0 rouge_score-0.1.2\n",
      "Requirement already satisfied: nltk in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\NLP\\fastai vision\\fastai-nlp-summarization.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scores \u001b[39m=\u001b[39m rouge_score\u001b[39m.\u001b[39mcompute(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     predictions\u001b[39m=\u001b[39m[generated_summary], references\u001b[39m=\u001b[39m[reference_summary]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m scores\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generated_summary' is not defined"
     ]
    }
   ],
   "source": [
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary], references=[reference_summary]\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Officers searched properties in the Waterfront Park and Colonsay View areas of the city on Wednesday.\n",
      "Detectives said three firearms, ammunition and a five-figure sum of money were recovered.\n",
      "A 26-year-old man who was arrested and charged appeared at Edinburgh Sheriff Court on Thursday.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "\n",
    "print(three_sentence_summary(dataset[\"test\"][1][\"document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[\"document\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\NLP\\fastai vision\\fastai-nlp-summarization.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m score \u001b[39m=\u001b[39m evaluate_baseline(dataset[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m], rouge_score)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m rouge_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mrouge1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrouge2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrougeL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrougeLsum\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rouge_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m((rn, \u001b[39mround\u001b[39;49m(score[rn]\u001b[39m.\u001b[39;49mmid\u001b[39m.\u001b[39;49mfmeasure \u001b[39m*\u001b[39;49m \u001b[39m100\u001b[39;49m, \u001b[39m2\u001b[39;49m)) \u001b[39mfor\u001b[39;49;00m rn \u001b[39min\u001b[39;49;00m rouge_names)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rouge_dict\n",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\NLP\\fastai vision\\fastai-nlp-summarization.ipynb Cell 16\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m score \u001b[39m=\u001b[39m evaluate_baseline(dataset[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m], rouge_score)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m rouge_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mrouge1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrouge2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrougeL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrougeLsum\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rouge_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((rn, \u001b[39mround\u001b[39m(score[rn]\u001b[39m.\u001b[39;49mmid\u001b[39m.\u001b[39mfmeasure \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m rn \u001b[39min\u001b[39;00m rouge_names)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rouge_dict\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(dataset[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id', 'input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Officers searched properties in the Waterfront Park and Colonsay View areas of the city on Wednesday.\\nDetectives said three firearms, ammunition and a five-figure sum of money were recovered.\\nA 26-year-old man who was arrested and charged appeared at Edinburgh Sheriff Court on Thursday.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = tokenized_datasets['test'][:int(len(tokenized_datasets['test']['document']) * .80)]\n",
    "test_split = tokenized_datasets['test']['document'][int(len(tokenized_datasets['test']['document']) * .80):]\n",
    "train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels_mask` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 715\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[0;32m    717\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[0;32m    719\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 26 at dim 1 (got 20)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\NLP\\fastai vision\\fastai-nlp-summarization.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m features \u001b[39m=\u001b[39m [tokenized_datasets[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m)]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_collator(features)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\data\\data_collator.py:580\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[1;34m(self, features, return_tensors)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m             feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([remainder, feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[1;32m--> 580\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(\n\u001b[0;32m    581\u001b[0m     features,\n\u001b[0;32m    582\u001b[0m     padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[0;32m    583\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[0;32m    584\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m    585\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m    586\u001b[0m )\n\u001b[0;32m    588\u001b[0m \u001b[39m# prepare decoder_input_ids\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    590\u001b[0m     labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    591\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    592\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mprepare_decoder_input_ids_from_labels\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2985\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   2982\u001b[0m             batch_outputs[key] \u001b[39m=\u001b[39m []\n\u001b[0;32m   2983\u001b[0m         batch_outputs[key]\u001b[39m.\u001b[39mappend(value)\n\u001b[1;32m-> 2985\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(batch_outputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    206\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[0;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[1;32m--> 210\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:731\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    727\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    728\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    729\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             )\n\u001b[1;32m--> 731\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    732\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    733\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    734\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m features (`\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         )\n\u001b[0;32m    738\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels_mask` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: labels_mask. If labels_mask are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 204045\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 204048\n",
      "  Number of trainable parameters = 406290432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64647e65e0b449891c37f9dd8046ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 6.00 GiB total capacity; 5.21 GiB already allocated; 0 bytes free; 5.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\NLP\\fastai vision\\fastai-nlp-summarization.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/NLP/fastai%20vision/fastai-nlp-summarization.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1506\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1747\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1749\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1752\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1753\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1754\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1755\u001b[0m ):\n\u001b[0;32m   1756\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2505\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2507\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2508\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2511\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2539\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2540\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2541\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2542\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2543\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1362\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1358\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1359\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1360\u001b[0m         )\n\u001b[1;32m-> 1362\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[0;32m   1363\u001b[0m     input_ids,\n\u001b[0;32m   1364\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1365\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1366\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[0;32m   1367\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1368\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1369\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1370\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1371\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1372\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1373\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1374\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1375\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1376\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1377\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1378\u001b[0m )\n\u001b[0;32m   1380\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(outputs[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1381\u001b[0m lm_logits \u001b[39m=\u001b[39m lm_logits \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\u001b[39m.\u001b[39mto(lm_logits\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1231\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1228\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m   1230\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1231\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1232\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1233\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1234\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1235\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1236\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1237\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1238\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[0;32m   1240\u001b[0m \u001b[39m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:850\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    843\u001b[0m         layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    844\u001b[0m             create_custom_forward(encoder_layer),\n\u001b[0;32m    845\u001b[0m             hidden_states,\n\u001b[0;32m    846\u001b[0m             attention_mask,\n\u001b[0;32m    847\u001b[0m             (head_mask[idx] \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 850\u001b[0m         layer_outputs \u001b[39m=\u001b[39m encoder_layer(\n\u001b[0;32m    851\u001b[0m             hidden_states,\n\u001b[0;32m    852\u001b[0m             attention_mask,\n\u001b[0;32m    853\u001b[0m             layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    854\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    855\u001b[0m         )\n\u001b[0;32m    857\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    859\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:325\u001b[0m, in \u001b[0;36mBartEncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(seq_len, batch, embed_dim)`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39m        returned tensors for more detail.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    324\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m--> 325\u001b[0m hidden_states, attn_weights, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[0;32m    326\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    327\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    328\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    329\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    331\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m    332\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:243\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m attention_mask\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m (bsz, \u001b[39m1\u001b[39m, tgt_len, src_len):\n\u001b[0;32m    240\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttention mask should be of size \u001b[39m\u001b[39m{\u001b[39;00m(bsz, \u001b[39m1\u001b[39m, tgt_len, src_len)\u001b[39m}\u001b[39;00m\u001b[39m, but is \u001b[39m\u001b[39m{\u001b[39;00mattention_mask\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         )\n\u001b[1;32m--> 243\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39;49mview(bsz, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads, tgt_len, src_len) \u001b[39m+\u001b[39;49m attention_mask\n\u001b[0;32m    244\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len)\n\u001b[0;32m    246\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(attn_weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 6.00 GiB total capacity; 5.21 GiB already allocated; 0 bytes free; 5.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "09d871c7bab6d3eee230d8ed3b9f49e61dfc3958b37ab798cf02e5a2f59d3730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
